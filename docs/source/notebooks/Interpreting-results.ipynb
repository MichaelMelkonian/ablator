{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting Results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This chapter covers about how to interpret results from the experiment directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To interpret the results:\n",
    "\n",
    "- The ablator initially consolidates the metrics from all the trials into a unified combined dataframe.\n",
    "- Utilize the pandas dataframe to generate insightful plots depicting the relationship between metrics and parameters outlined in the configuration."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "from ablator.analysis.results import Results # for formatting results\n",
    "from ablator import PlotAnalysis, Optim # for plotting\n",
    "\n",
    "from ablator import ParallelConfig, ModelConfig, configclass # for configs\n",
    "\n",
    "from pathlib import Path # for defining path\n",
    "import pandas as pd # for reading dataframe\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To create pandas dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define/Import all the custom configs used during the HPO (if using separate files for HPO and Analysis)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "@configclass\n",
    "class CustomModelConfig(ModelConfig):\n",
    "  num_filter1: int\n",
    "  num_filter2: int\n",
    "  activation: str\n",
    "\n",
    "@configclass\n",
    "class CustomParallelConfig(ParallelConfig):\n",
    "  model_config: CustomModelConfig\n",
    "  ```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generating results\n",
    "\n",
    "The ````Results```` class is responsible for processing the results within all the trial directories.\n",
    "\n",
    "The ````read_results()```` method from the ````Result```` class reads multiple results from the experiment directory using Ray for parallel processing. It returns all the combined metrics as a pandas DataFrame.\n",
    "\n",
    "In this code snippet, a directory path is defined. Results are read from that directory. Subsequently, the results are saved to a CSV file.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "directory_path = Path('./experiment_1901_aa90')\n",
    "\n",
    "results = Results(config = CustomParallelConfig, experiment_dir=directory_path, use_ray=True)\n",
    "\n",
    "df = results.read_results(config_type=CustomParallelConfig, experiment_dir=directory_path)\n",
    "\n",
    "df.to_csv(\"results.csv\", index=False)\n",
    "````"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting graphs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PlotAnalysis class is utilized for plotting graphs.\n",
    "\n",
    "The responsibilities of the PlotAnalysis class include:\n",
    "\n",
    "* Generating plots between the provided metrics and parameters.\n",
    "* Mapping the output and attribute names to user provided names for better readability.\n",
    "* Storing the generated plots in the desired directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the dataset, so it gives the best validation accuracy for each trial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "df = (\n",
    "        df.groupby(\"path\")\n",
    "        .apply(lambda x: x.sort_values(\"val_accuracy\", na_position=\"first\").iloc[-1])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dictionaries that map the configuration parameters [categorical + numerical] to custom labels for plots.\n",
    "\n",
    "The keys are the parameters inside the configuration file, and the values are the custom names.\n",
    "\n",
    "Renaming attributes/metrics to custom names is optional. If not provided the names will be the default like \"train_config.batch_size\"."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "categorical_name_remap = {\n",
    "        \"model_config.activation\": \"Activation\",\n",
    "    }\n",
    "numerical_name_remap = {\n",
    "        \"model_config.num_filter1\": \"N. Filter 1\",\n",
    "        \"model_config.num_filter2\": \"N. Filter 2\",\n",
    "        \"train_config.optimizer_config.arguments.lr\": \"Learning Rate\",\n",
    "    }\n",
    "\n",
    "attribute_name_remap = {**categorical_name_remap, **numerical_name_remap}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Finally, pass the following to the ````PlotAnalysis````:\n",
    "\n",
    "* dataframe: Pandas dataframe.\n",
    "* cache: Whether to cache results.\n",
    "* optim_metrics: A dictionary mapping metric names to optimization directions.\n",
    "* numerical_attributes: List of all the numerical attributes plotted with respect to metrics.\n",
    "* categorical_attributes: List of all the categorical attributes plotted with respect to metrics.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "analysis = PlotAnalysis(\n",
    "        df,\n",
    "        save_dir=\"./plots\",\n",
    "        cache=True,\n",
    "        optim_metrics={\"val_accuracy\": Optim.max},\n",
    "        numerical_attributes=list(numerical_name_remap.keys()),\n",
    "        categorical_attributes=list(categorical_name_remap.keys()),\n",
    "    )\n",
    "\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ````main_figures()```` method is responsible for generating graphs, specifically a violin plot for numerical attributes and a linear plot for categorical values.\n",
    "\n",
    "To generate these plots, pass the mappings of metrics and attributes dictionary."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "analysis.make_figures(\n",
    "        metric_name_remap={\n",
    "            \"val_accuracy\": \"Validation Accuracy\",\n",
    "        },\n",
    "        attribute_name_remap= attribute_name_remap\n",
    "    )\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the directory \"plots\" will contain all the plots of the HPO experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see the plot generated for our previous HPO tutorial."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linearplots\n",
    "\n",
    "<img src=\"./Images/model_config.num_filter1.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Number of Filters in Layer 1\">\n",
    "<img src=\"./Images/model_config.num_filter2.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Number of Filters in Layer 2\">\n",
    "<img src=\"./Images/train_config.optimizer_config.arguments.lr.png\" width=\"300\" height=\"300\" alt=\"Validation Accuracy vs. Learning Rate\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, with increase in learning rate, the model's validation accuracy decreases. Similarly, with \"N. Filter 1\" decreases the model's performance and the validation. Finally, the \"N. Filter 2\" hyperparameter does not affect the model's accuracy. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Violinplots\n",
    "\n",
    "\n",
    "<img src=\"./Images/model_config.activation.png\" width=\"600\" height=\"380\" alt=\"Validation Accuracy vs. Activations\">\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For activation functions, we can see \"relu\" and \"leaky relu\" perform better for this problem. Training with \"elu\" scores low accuracy on validation set.\n",
    "Overall, leaky-relu gave the highest accuracy for the experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusion\n",
    "\n",
    "Thus, we have completed the analysis part of the tutorial. We saw the complete pipeline to use ablator to train models. This starts with  prototyping models to analyzing the HPO results. We have significantly spend less time on writing boiler plate code while getting the benefits of parallel-training, storing metrics and analysis."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
