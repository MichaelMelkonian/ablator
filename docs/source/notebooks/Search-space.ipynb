{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "from ablator import ModelConfig, OptimizerConfig, TrainConfig, RunConfig, ParallelConfig\n",
    "from ablator import ModelWrapper, ProtoTrainer, Stateless, Derived, ParallelTrainer\n",
    "from ablator.main.configs import SearchSpace\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ablator.main.configs import ParallelConfig, SearchSpace\n",
    "search_space = {\n",
    "    \"train_config.optimizer_config.arguments.lr\": SearchSpace(\n",
    "        value_range=[0.05, 0.1], value_type=\"float\"\n",
    "    ),\n",
    "    \"model_config.hidden_size\": SearchSpace(\n",
    "        value_range=[250, 500], value_type=\"int\"\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "class CustomModelConfig(ModelConfig):\n",
    "    input_size :int\n",
    "    hidden_size :int\n",
    "    num_classes :int \n",
    "\n",
    "\n",
    "model_config = CustomModelConfig(input_size = 28*28, hidden_size = 256, num_classes = 10)\n",
    "\n",
    "optimizer_config = OptimizerConfig(\n",
    "    name=\"adam\", \n",
    "    arguments={\"lr\": 0.001}\n",
    ")\n",
    "\n",
    "train_config = TrainConfig(\n",
    "    dataset=\"Fashion-mnist\",\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    optimizer_config=optimizer_config,\n",
    "    scheduler_config=None,\n",
    "    rand_weights_init = True\n",
    ")\n",
    "\n",
    "class CustomParallelConfig(ParallelConfig):\n",
    "    model_config: CustomModelConfig\n",
    "\n",
    "parallel_config = CustomParallelConfig(\n",
    "    train_config=train_config,\n",
    "    model_config = model_config,\n",
    "    device=\"cpu\",\n",
    "    amp=False,\n",
    "    search_space=search_space,\n",
    "    optim_metrics={\"val_loss\": \"min\"},\n",
    "    total_trials=10,\n",
    "    concurrent_trials=10,\n",
    "    gpu_mb_per_experiment=100,\n",
    "    cpus_per_experiment=0.5,\n",
    "    random_seed = 123\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.FashionMNIST(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class FashionMNISTModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(FashionMNISTModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Adding loss to the model.\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, config: CustomModelConfig) -> None:\n",
    "        super().__init__()\n",
    "        input_size = config.input_size\n",
    "        hidden_size = config.hidden_size\n",
    "        num_classes = config.num_classes\n",
    "        \n",
    "        self.model = FashionMNISTModel(input_size, hidden_size, num_classes)\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        out = self.model(x)\n",
    "        loss = None\n",
    "\n",
    "        if labels is not None:\n",
    "            loss = self.loss(out, labels)\n",
    "\n",
    "        out = out.argmax(dim=-1)\n",
    "\n",
    "        return {\"y_pred\": out, \"y_true\": labels}, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy(y_true, y_pred):\n",
    "    return accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "\n",
    "def my_f1_score(y_true, y_pred):\n",
    "    return f1_score(y_true.flatten(), y_pred.flatten(), average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModelWrapper(ModelWrapper):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def make_dataloader_train(self, run_config: ParallelConfig):\n",
    "        return train_dataloader\n",
    "\n",
    "    def make_dataloader_val(self, run_config: ParallelConfig):\n",
    "        return test_dataloader\n",
    "\n",
    "    def evaluation_functions(self):\n",
    "        return {\n",
    "            \"accuracy\": my_accuracy,\n",
    "            \"f1_score\": my_f1_score\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-13 15:02:27,992\tINFO usage_lib.py:521 -- Usage stats collection is enabled. To disable this, add `--disable-usage-stats` to the command that starts the cluster, or run the following command: `ray disable-usage-stats` before starting the cluster. See https://docs.ray.io/en/master/cluster/usage-stats.html for more details.\n",
      "2023-06-13 15:02:27,992\tINFO scripts.py:702 -- Local node IP: 127.0.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"c:\\Users\\user\\Desktop\\ablator\\env\\Scripts\\ray.exe\\__main__.py\", line 7, in <module>\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ray\\scripts\\scripts.py\", line 2386, in main\n",
      "    return cli()\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\click\\core.py\", line 1130, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\click\\core.py\", line 1055, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\click\\core.py\", line 1657, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\click\\core.py\", line 1404, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\click\\core.py\", line 760, in invoke\n",
      "    return __callback(*args, **kwargs)\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ray\\autoscaler\\_private\\cli_logger.py\", line 852, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ray\\scripts\\scripts.py\", line 722, in start\n",
      "    raise ConnectionError(\n",
      "ConnectionError: Ray is trying to start at 127.0.0.1:6379, but is already running at 127.0.0.1:6379. Please specify a different port using the `--port` flag of `ray start` command.\n"
     ]
    }
   ],
   "source": [
    "!ray start --head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-13 15:02:29,604\tINFO worker.py:1352 -- Connecting to existing Ray cluster at address: 127.0.0.1:6379...\n",
      "2023-06-13 15:02:29,688\tINFO worker.py:1538 -- Connected to Ray cluster.\n",
      "2023-06-13 15:02:29,928\tINFO packaging.py:546 -- Creating a file package for local directory 'c:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ablator'.\n",
      "2023-06-13 15:02:30,059\tINFO packaging.py:373 -- Pushing file package 'gcs://_ray_pkg_28867304fe7d6a3a.zip' (0.58MiB) to Ray cluster...\n",
      "2023-06-13 15:02:30,070\tINFO packaging.py:386 -- Successfully pushed file package 'gcs://_ray_pkg_28867304fe7d6a3a.zip'.\n",
      "2023-06-13 15:02:30,422\tINFO packaging.py:546 -- Creating a file package for local directory 'c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks'.\n",
      "2023-06-13 15:02:30,494\tWARNING packaging.py:420 -- File c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\data\\FashionMNIST\\raw\\train-images-idx3-ubyte is very large (44.86MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\data\\FashionMNIST\\raw\\train-images-idx3-ubyte']})`\n",
      "2023-06-13 15:02:30,705\tWARNING packaging.py:420 -- File c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz is very large (25.20MiB). Consider adding this file to the 'excludes' list to skip uploading it: `ray.init(..., runtime_env={'excludes': ['c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz']})`\n",
      "2023-06-13 15:02:30,884\tINFO packaging.py:373 -- Pushing file package 'gcs://_ray_pkg_da11a0a405d13373.zip' (82.05MiB) to Ray cluster...\n",
      "2023-06-13 15:02:32,460\tINFO packaging.py:386 -- Successfully pushed file package 'gcs://_ray_pkg_da11a0a405d13373.zip'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-13 15:02:32: Model directory: None\n",
      "2023-06-13 15:02:32: Creating new model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\experiment_1901_6c10\\1901_6c10_optuna.db exists. Please remove before starting a study.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      5\u001b[0m WORKING_DIRECTORY \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mgetcwd()\n\u001b[0;32m      7\u001b[0m ablator \u001b[39m=\u001b[39m ParallelTrainer(\n\u001b[0;32m      8\u001b[0m     wrapper\u001b[39m=\u001b[39mwrapper,\n\u001b[0;32m      9\u001b[0m     run_config\u001b[39m=\u001b[39mparallel_config,\n\u001b[0;32m     10\u001b[0m )\n\u001b[1;32m---> 11\u001b[0m metrics \u001b[39m=\u001b[39m ablator\u001b[39m.\u001b[39;49mlaunch(\n\u001b[0;32m     12\u001b[0m     working_directory\u001b[39m=\u001b[39;49mWORKING_DIRECTORY,\n\u001b[0;32m     13\u001b[0m   ray_head_address\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     14\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ablator\\main\\mp.py:529\u001b[0m, in \u001b[0;36mParallelTrainer.launch\u001b[1;34m(self, working_directory, auxilary_modules, ray_head_address, resume)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m:\n\u001b[0;32m    528\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 529\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_init_state(\n\u001b[0;32m    530\u001b[0m     working_dir\u001b[39m=\u001b[39;49mworking_directory,\n\u001b[0;32m    531\u001b[0m     address\u001b[39m=\u001b[39;49mray_head_address,\n\u001b[0;32m    532\u001b[0m     modules\u001b[39m=\u001b[39;49mauxilary_modules,\n\u001b[0;32m    533\u001b[0m     resume\u001b[39m=\u001b[39;49mresume,\n\u001b[0;32m    534\u001b[0m )\n\u001b[0;32m    536\u001b[0m futures \u001b[39m=\u001b[39m []\n\u001b[0;32m    537\u001b[0m trials: \u001b[39mlist\u001b[39m[ParallelConfig] \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment_state\u001b[39m.\u001b[39mpending_trials\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ablator\\main\\mp.py:400\u001b[0m, in \u001b[0;36mParallelTrainer._init_state\u001b[1;34m(self, working_dir, address, modules, resume)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m_init_state()\n\u001b[0;32m    399\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msync_down()\n\u001b[1;32m--> 400\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperiment_state \u001b[39m=\u001b[39m ExperimentState(\n\u001b[0;32m    401\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperiment_dir, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_config, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlogger, resume\u001b[39m=\u001b[39;49mresume\n\u001b[0;32m    402\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\user\\Desktop\\ablator\\env\\lib\\site-packages\\ablator\\main\\state.py:453\u001b[0m, in \u001b[0;36mExperimentState.__init__\u001b[1;34m(self, experiment_dir, config, logger, resume)\u001b[0m\n\u001b[0;32m    451\u001b[0m optuna_db_path \u001b[39m=\u001b[39m experiment_dir\u001b[39m.\u001b[39mjoinpath(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstudy_name\u001b[39m}\u001b[39;00m\u001b[39m_optuna.db\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    452\u001b[0m \u001b[39mif\u001b[39;00m optuna_db_path\u001b[39m.\u001b[39mexists() \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m resume:\n\u001b[1;32m--> 453\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    454\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00moptuna_db_path\u001b[39m}\u001b[39;00m\u001b[39m exists. Please remove before starting a study.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    455\u001b[0m     )\n\u001b[0;32m    457\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptuna_state \u001b[39m=\u001b[39m OptunaState(\n\u001b[0;32m    458\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msqlite:///\u001b[39m\u001b[39m{\u001b[39;00moptuna_db_path\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    459\u001b[0m     study_name\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39muid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    462\u001b[0m     search_space\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39msearch_space,\n\u001b[0;32m    463\u001b[0m )\n\u001b[0;32m    464\u001b[0m experiment_state_db \u001b[39m=\u001b[39m experiment_dir\u001b[39m.\u001b[39mjoinpath(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mstudy_name\u001b[39m}\u001b[39;00m\u001b[39m_state.db\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: c:\\Users\\user\\Desktop\\ablator\\docs\\source\\notebooks\\experiment_1901_6c10\\1901_6c10_optuna.db exists. Please remove before starting a study."
     ]
    }
   ],
   "source": [
    "\n",
    "wrapper = MyModelWrapper(\n",
    "    model_class=MyModel,\n",
    ")\n",
    "\n",
    "WORKING_DIRECTORY = os.getcwd()\n",
    "\n",
    "ablator = ParallelTrainer(\n",
    "    wrapper=wrapper,\n",
    "    run_config=parallel_config,\n",
    ")\n",
    "metrics = ablator.launch(\n",
    "    working_directory=WORKING_DIRECTORY,\n",
    "  ray_head_address=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
