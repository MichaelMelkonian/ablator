{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment output directory"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, you will familiarize yourself with the experiment's output folder structure. Some of the files can be used directly to quickly draw conclusions about the experiment's results. Others can be used to create custom visualizations with Analysis module.\n",
    "\n",
    "After running the experiments from the Hyperparameter Optimization (HPO) tutorial, the results are cached in the directory: `/tmp/experiments`, as specified in the configurations `experiment_dir`. The results directory follows these structures:\n",
    "\n",
    "```\n",
    "- tmp/experiments\n",
    "    - experiment_<experiment_id>\n",
    "        - <trial1_id>\n",
    "          - best_checkpoints/\n",
    "          - checkpoints/\n",
    "          - dashboard/\n",
    "          - config.yaml\n",
    "          - metadata.json\n",
    "          - results.json\n",
    "          - train.log\n",
    "        - <trial2_id>\n",
    "        - <trial3_id>\n",
    "        - ...\n",
    "        - <experiment_id>_optuna.db\n",
    "        - <experiment_id>_state.db\n",
    "        - default_config.yaml\n",
    "        - mp.log\n",
    "```\n",
    "\n",
    "As you can see, there are two levels of directories: one for the experiment, and one for the trials.\n",
    "\n",
    "- The `experiment_<experiment_id>` directory:\n",
    "  - `<experiment_id>_optuna.db`: for each trial, after finished training, its metrics (those to be optimized) will be added to the experiment state database (via optuna_study.tell()). Optuna will use this as a base to explore the search space based on the results so far. The content of this database is out of this tutorial's scope, since it's used by `optuna` to perform hyperparamweters exploration.\n",
    "  - `<experiment_id>_state.db`: for each trial, after finished training, its metrics (those to be optimized), configuration, and training state (RUNNING, WAITING, etc.), will be added to the experiment state database. (Probably be accessed by the dashboard API)\n",
    "  - `default_config.yaml`: the overrall configurations for model, training and hyperparameters tuning. Note that configurations for hyperparameters will be changed in each trial's `config.yaml` file that's specific to that trial only.\n",
    "  - `mp.log`: console infomation during the running experiment. This gives information about the trials that's running in parallel, how many that's running and how many that's terminated.\n",
    "\n",
    "- Trial directories, each contains:\n",
    "  - `train.log`: console infomation during the training process of the running trial. This log reports metrics from training and from evaluation. These metrics include static (e.g best loss value, the current iteration, current epoch, best iteration so far, total steps, current learning rate) and moving average metrics (e.g training loss, validation loss, user-defined metrics f1 score, precision, etc).\n",
    "  - `results.json`: helps keep track of the running trial. This includes an json object for each of the epochs. This is where all metrics in the `train.log` are stored as json objects.\n",
    "    ```\n",
    "    {\n",
    "    \"train_loss\": 4.234887647596995,\n",
    "    \"val_loss\": NaN,\n",
    "    \"train_accuracy\": 0.463046875,\n",
    "    \"val_accuracy\": NaN,\n",
    "    \"best_iteration\": 0,\n",
    "    \"best_loss\": Infinity,\n",
    "    \"current_epoch\": 1,\n",
    "    \"current_iteration\": 1875,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.0025929597250393165,\n",
    "    \"total_steps\": 18750\n",
    "    },\n",
    "    {\n",
    "    \"train_loss\": 1.5882160221735637,\n",
    "    \"val_loss\": 1.4797034080797873,\n",
    "    \"train_accuracy\": 0.4984375,\n",
    "    \"val_accuracy\": 0.5128,\n",
    "    \"best_iteration\": 1875,\n",
    "    \"best_loss\": 1.4797034080797873,\n",
    "    \"current_epoch\": 2,\n",
    "    \"current_iteration\": 3750,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.0025929597250393165,\n",
    "    \"total_steps\": 18750\n",
    "    },\n",
    "    ...\n",
    "    {\n",
    "    \"train_loss\": 1.4190918445428213,\n",
    "    \"val_loss\": 1.670326127942403,\n",
    "    \"train_accuracy\": 0.59286328125,\n",
    "    \"val_accuracy\": 0.5895444444444444,\n",
    "    \"best_iteration\": 3750,\n",
    "    \"best_loss\": 1.461920569594295,\n",
    "    \"current_epoch\": 10,\n",
    "    \"current_iteration\": 18750,\n",
    "    \"epochs\": 10,\n",
    "    \"learning_rate\": 0.0025929597250393165,\n",
    "    \"total_steps\": 18750\n",
    "    }\n",
    "\n",
    "    ```\n",
    "    As you can observe from this sample `results.json` file from HPO tutorial, there are 10 json objects, each represents metrics of one epoch. `best_iteration` and `best_loss` values give us information about the best performing iteration.\n",
    "  - `config.yaml`: configuration details that's specific to the running trial.\n",
    "  - `checkpoints/`: this directory stores checkpoints for the trained model, which includes the model parameters, the optimizer (and/or scheduler), and all the metrics computed using this model. Config parameter `keep_n_checkpoints` control the numbers of checkpoints kept in this folder. You can play around with the checkpoint files by loading the pt file with pytorch. For example, you can load the model parameters and optimizer state with the following code:\n",
    "    ```python\n",
    "    import torch\n",
    "\n",
    "    checkpoint_path = \"tmp/experiments/experiment_<experiment_id>/<trial1_id>/checkpoints/<ckpt_name>.pt\"\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "    ```\n",
    "    ```\n",
    "    {'run_config': {'model_config': {'input_size': 784,\n",
    "    'hidden_size': 453,\n",
    "    'num_classes': 10},\n",
    "    'experiment_dir': ...,\n",
    "    'random_seed': 123,\n",
    "    'train_config': {...},\n",
    "    'scheduler_config': None,\n",
    "    'total_trials': 1,\n",
    "    'concurrent_trials': 1,\n",
    "    'search_space': {...},\n",
    "    'optim_metrics': {'val_loss': <Optim.min: 'min'>},\n",
    "    ...\n",
    "    'metrics': {'train_loss': 1.2681676818847656,\n",
    "      'val_loss': 1.2884625773460339,\n",
    "      'train_accuracy': 0.5673828125,\n",
    "      ...},\n",
    "    'model': OrderedDict([('model.fc1.weight',\n",
    "                  tensor([[-0.0115, -0.0191,  0.0091,  ...,  0.0055,  0.0072, -0.0133],\n",
    "                          [ 0.0038, -0.0020,  0.0061,  ..., -0.1115,  0.0072,  0.0010],\n",
    "                          [ 0.0108, -0.0148,  0.0069,  ...,  0.1052, -0.0180, -0.0165],\n",
    "                          ...,\n",
    "                          [-0.0234,  0.0091, -0.0088,  ...,  0.0090,  0.0136, -0.0035],\n",
    "                          [ 0.0115,  0.0197, -0.0017,  ..., -0.1034,  0.0064, -0.0030],\n",
    "                          [-0.0083,  0.0073,  0.0204,  ..., -0.0111,  0.0014,  0.0003]]))\n",
    "                          ...\n",
    "                          ])\n",
    "      ...\n",
    "      }}\n",
    "    ```\n",
    "  - `best_checkpoints`: this directory stores the best checkpoints for the trained model.\n",
    "  - `dashboard/`: directory to cache those metrics data, and you can use Tensorboard for visualization of how metrics oscilates while training: Install `tensorboard` and load using `%load_ext tensorboard` if using notebook, then run `%tensorboard --logdir /tmp/experiments/experiment_<experiment_id> --port [port]`. E.g:\n",
    "    ```\n",
    "    %load_ext tensorboard\n",
    "    %tensorboard --logdir /tmp/experiments/experiment_1901_aa90 --port 6008\n",
    "    ```\n",
    "    ![TensorBoard-Output](./Images/tensorboard-output.jpg)\n",
    "  - `metadata.json`: keeps track of the training progess: log iteration (specifies the latest iteration that logs the results to files), checkpoint iteration specifies which iteration a checkpoint is been saved and which iteration is the best one.\n",
    "\n",
    "In the folling tutorial, we will use Analysis module to visualize these results so we can draw better conclusions about the experiment's results."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
